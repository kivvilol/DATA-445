{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3b38dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso =  63410.43817928265 , Ridge =  68851.82257152862\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "\n",
    "# defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'webster-data445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# defining the csv file\n",
    "file_key = 'Fish.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "# reading the csv file\n",
    "fish = pd.read_csv(file_content_stream)\n",
    "fish.head()\n",
    "\n",
    "# defining the input and target variable\n",
    "X = fish[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
    "Y = fish['Weight']\n",
    "\n",
    "# splitting into train (80%) and test (20%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "# performing LASSO as variable selector\n",
    "# First we need to estimate lambda\n",
    "lasso_cv = LassoCV(normalize = True, cv = 5, max_iter = 10000).fit(X_train, Y_train)\n",
    "lasso_alpha = lasso_cv.alpha_\n",
    "\n",
    "# building lasso model\n",
    "lasso_md = Lasso(alpha = lasso_alpha, normalize = True, max_iter = 10000).fit(X_train, Y_train)\n",
    "lasso_md.coef_\n",
    "\n",
    "# dropping variables\n",
    "X_train = X_train.drop(columns = ['Length2', 'Length3'], axis = 1)\n",
    "X_test = X_test.drop(columns = ['Length2', 'Length3'], axis = 1)\n",
    "\n",
    "# creating l2 normalization function\n",
    "def l2_normalization(X):\n",
    "    \n",
    "    x_mean = np.mean(X)\n",
    "    l2 = np.sqrt(sum(X**2))\n",
    "    return (X - x_mean) / l2\n",
    "\n",
    "X_train = X_train.apply(l2_normalization, axis = 1)\n",
    "X_test = X_test.apply(l2_normalization, axis = 1)\n",
    "\n",
    "# linear regression\n",
    "md1 = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "# preicting on test\n",
    "md1_pred = md1.predict(X_test)\n",
    "md1_pred\n",
    "\n",
    "# computing the mse\n",
    "mse1 = np.mean(np.power(md1_pred - Y_test, 2))\n",
    "mse1\n",
    "\n",
    "# ridge regression\n",
    "ridge_cv = RidgeCV(alphas = [0.001, 0.01, 0.1, 1, 10, 100], cv = 5). fit(X_train, Y_train)\n",
    "ridge_alpha = ridge_cv.alpha_\n",
    "\n",
    "# Building the ridge model\n",
    "ridge_md = Ridge(alpha = ridge_alpha).fit(X_train, Y_train)\n",
    "\n",
    "# predicting on test\n",
    "md2_pred = ridge_md.predict(X_test)\n",
    "md2_pred\n",
    "\n",
    "# computing the mse\n",
    "mse2 = np.mean(np.power(md2_pred - Y_test, 2))\n",
    "mse2\n",
    "\n",
    "print('Lasso = ', mse1, ',','Ridge = ', mse2)\n",
    "\n",
    "# We would use the Lasso model (model 1) because the mse is a smaller value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
